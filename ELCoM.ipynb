{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.accuracy_metrics import AccuracyMetrics\n",
    "from metrics.similarity_metrics import CosineSimilarity\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders.elco_dataloader import get_loaders\n",
    "train_loader, test_loader = get_loaders(\"data/ELCo.csv\", batch_size=1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class TeacherModel():\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.model.encode(x, convert_to_tensor=True)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.encode(x)\n",
    "\n",
    "class StudentModel():\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.encode(x, convert_to_tensor=True, )\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from itertools import chain\n",
    "\n",
    "class ELCoMTrainer:\n",
    "    def __init__(self, teacher_model, student_model, optim, lr, accuracy_metric):\n",
    "        self.teacher = teacher_model\n",
    "        self.student = student_model\n",
    "        # self.teacher_optimizer = optim(self.teacher.model._first_module().parameters(), lr=lr)\n",
    "        self.student_optimizer = optim(self.student.model._first_module().parameters(), lr=lr)\n",
    "        self.accuracy_metric = accuracy_metric\n",
    "        self.optim = optim\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.cosine = nn.CosineSimilarity()\n",
    "        self.similarity = CosineSimilarity()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def train(self, train_loader, epochs):\n",
    "        # self.teacher.train()\n",
    "        # self.teacher.to(self.device)\n",
    "        # self.student.train()\n",
    "        # self.student.to(self.device)\n",
    "        total_loss = 0\n",
    "        for epoch in range(epochs):\n",
    "            for x, y in tqdm(train_loader):\n",
    "                teacher_en = Variable(self.teacher(x), requires_grad=True).mean(axis=0).unsqueeze(0)\n",
    "                student_en = Variable(self.student(x), requires_grad=True).mean(axis=0).unsqueeze(0)\n",
    "                student_em = Variable(self.student(y), requires_grad=True)\n",
    "                loss = self.mse(student_en, teacher_en) + self.mse(student_em, teacher_en)\n",
    "                + self.cosine(student_en, student_em).item()\n",
    "                # self.teacher_optimizer.zero_grad()\n",
    "                self.student_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # self.teacher_optimizer.step()\n",
    "                self.student_optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            print(f\"Epoch {epoch + 1} loss: {total_loss / len(train_loader)}\")\n",
    "        print(\"Training finished\")\n",
    "    \n",
    "    def test(self, test_loader):\n",
    "        \n",
    "        accuracy = 0\n",
    "        for x, y in tqdm(test_loader):\n",
    "            y = y[0]\n",
    "            rank_scores = []\n",
    "            y_score = self.student(y)\n",
    "            for rank, sentences in x.items():\n",
    "                sentences = list(chain(*sentences))\n",
    "                embeddings = self.student(sentences).mean(axis=0) # simple mean\n",
    "                rank_scores.append((self.similarity(embeddings, y_score).cpu().detach().numpy()[0], rank))\n",
    "            sorted_rank_scores = sorted(rank_scores, key=lambda x: x[0], reverse=True)\n",
    "            accuracy += self.accuracy_metric(sorted_rank_scores)\n",
    "        return accuracy / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [04:06<00:00,  1.47s/it]\n",
      "  0%|          | 0/168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.3136802017688751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [04:43<00:00,  1.69s/it]\n",
      "  0%|          | 0/168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 0.2646413743495941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [04:12<00:00,  1.50s/it]\n",
      "  0%|          | 0/168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 0.2129564881324768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [04:02<00:00,  1.44s/it]\n",
      "  0%|          | 0/168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 0.2808777689933777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [04:09<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 0.2949393689632416\n",
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "teacher_model = TeacherModel()\n",
    "student_model = StudentModel()\n",
    "lr = 1e-3\n",
    "trainer = ELCoMTrainer(teacher_model, student_model, Adam, lr, AccuracyMetrics().accuracy)\n",
    "trainer.train(train_loader, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:21<00:00,  1.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.150462962962963"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ELCoMTrainer(trainer.teacher, trainer.student, Adam, lr, AccuracyMetrics().accuracy)\n",
    "trainer.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
