{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders.elco_dataloader import get_loaders\n",
    "train_loader, test_loader = get_loaders(\"data/ELCo.csv\", batch_size=1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: [('national park',), ('national park',)],\n",
       "  1: [('TOP arrow',), ('national park',), ('TOP arrow national park',)],\n",
       "  2: [('up arrow',), ('national park',), ('up arrow national park',)],\n",
       "  3: [('TOP arrow',),\n",
       "   ('water wave',),\n",
       "   ('national park',),\n",
       "   ('TOP arrow water wave national park',)],\n",
       "  4: [('national park',), ('national park',)],\n",
       "  5: [('up arrow',), ('national park',), ('up arrow national park',)],\n",
       "  6: [('ladder',), ('national park',), ('ladder national park',)],\n",
       "  7: [('water wave',),\n",
       "   ('backhand index pointing up',),\n",
       "   ('water wave backhand index pointing up',)]},\n",
       " ('high river',)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cross mark',), ('page facing up',), ('cross mark page facing up',)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cross mark', 'page facing up', 'cross mark page facing up']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = iter(train_loader).next()\n",
    "from itertools import chain\n",
    "print(value[0][0])\n",
    "list(chain(*value[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: [('sun',),\n",
       "   ('hot springs',),\n",
       "   ('hot face',),\n",
       "   ('thermometer',),\n",
       "   ('sun hot springs hot face thermometer',)],\n",
       "  1: [('TOP arrow',), ('hot face',), ('TOP arrow hot face',)],\n",
       "  2: [('thermometer',),\n",
       "   ('face with thermometer',),\n",
       "   ('thermometer face with thermometer',)],\n",
       "  3: [('face with thermometer',),\n",
       "   ('woozy face',),\n",
       "   ('hot face',),\n",
       "   ('face with thermometer woozy face hot face',)],\n",
       "  4: [('hot face',),\n",
       "   ('hot springs',),\n",
       "   ('sun',),\n",
       "   ('bed',),\n",
       "   ('hot face hot springs sun bed',)],\n",
       "  5: [('thermometer',), ('sun',), ('thermometer sun',)],\n",
       "  6: [('face with thermometer',), ('face with thermometer',)],\n",
       "  7: [('thermometer',),\n",
       "   ('face with thermometer',),\n",
       "   ('backhand index pointing up',),\n",
       "   ('thermometer face with thermometer backhand index pointing up',)]},\n",
       " ('high temperature',)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(test_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hot springs',), ('foot',), ('leg',), ('nose',), ('ear',), ('hand with fingers splayed',), ('hot springs foot leg nose ear hand with fingers splayed',)]\n",
      "['hot springs', 'foot', 'leg', 'nose', 'ear', 'hand with fingers splayed', 'hot springs foot leg nose ear hand with fingers splayed']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((384,), (384,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "x, y = iter(train_loader).next()\n",
    "# flatten list of lists\n",
    "print(x[0])\n",
    "x = list(chain(*x[0]))\n",
    "print(x)\n",
    "x = model.encode(x)\n",
    "y = model.encode(y[0])\n",
    "x = x.mean(axis=0) # Going with a simple mean for now\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class SimilarityMetrics:\n",
    "    def __init__(self, similarity_metric):\n",
    "        self.similarity_metric = similarity_metric\n",
    "    \n",
    "    def type_check(self, embedding):\n",
    "        if isinstance(embedding, list):\n",
    "            embedding = torch.stack(embedding)\n",
    "        if isinstance(embedding, np.ndarray):\n",
    "            embedding = torch.from_numpy(embedding)\n",
    "        return embedding\n",
    "    \n",
    "    def __call__(self, x_embedding, y_embedding):\n",
    "        return self.similarity_metric(x_embedding, y_embedding)\n",
    "\n",
    "class CosineSimilarity(SimilarityMetrics):\n",
    "    def __init__(self):\n",
    "        super().__init__(torch.nn.CosineSimilarity(dim=0))\n",
    "    \n",
    "    def __call__(self, x_embedding, y_embedding):\n",
    "        x_embedding = self.type_check(x_embedding)\n",
    "        y_embedding = self.type_check(y_embedding)\n",
    "        \n",
    "        if x_embedding.ndim == 1:\n",
    "            x_embedding = x_embedding.view(-1, 1)\n",
    "        if y_embedding.ndim == 1:\n",
    "            y_embedding = y_embedding.view(-1, 1)\n",
    "        return super().__call__(x_embedding, y_embedding)\n",
    "\n",
    "class EucledianDistance(SimilarityMetrics):\n",
    "    def __init__(self):\n",
    "        super().__init__(torch.nn.PairwiseDistance(p=2))\n",
    "    \n",
    "    def __call__(self, x_embedding, y_embedding):\n",
    "        x_embedding = self.type_check(x_embedding)\n",
    "        y_embedding = self.type_check(y_embedding)\n",
    "        \n",
    "        if x_embedding.ndim == 1:\n",
    "            x_embedding = x_embedding.unsqueeze(0)\n",
    "        if y_embedding.ndim == 1:\n",
    "            y_embedding = y_embedding.unsqueeze(0)\n",
    "        return -super().__call__(x_embedding, y_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5228])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CosineSimilarity()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(x).unsqueeze(0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8624])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EucledianDistance()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.encode(x)\n",
    "\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.model.encode(x), self.model.encode(y)\n",
    "\n",
    "class ELCoM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.teacher = TeacherModel()\n",
    "        self.student = StudentModel()\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        teacher_en = self.teacher(x)\n",
    "        student_en, student_em = self.student(x, y)\n",
    "        return teacher_en, student_en, student_em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shorts',), ('alien',), ('shorts alien',)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = iter(train_loader).next()\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 768), (8, 768), (1, 768))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ELCoM()\n",
    "teacher_en, student_en, student_em = model(x, y)\n",
    "teacher_en.shape, student_en.shape, student_em.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30831382,  0.3514907 ,  0.6976047 , ...,  0.53146845,\n",
       "         0.8605992 ,  0.08637048],\n",
       "       [ 0.15562136,  0.8941867 ,  0.88533294, ...,  0.4209026 ,\n",
       "         0.46350625,  0.20158474],\n",
       "       [-0.01096022,  0.760641  ,  1.3321491 , ..., -0.32805952,\n",
       "         0.69355524, -0.15827833],\n",
       "       ...,\n",
       "       [-0.5131449 ,  0.40606   ,  0.7688541 , ...,  0.19555578,\n",
       "         0.533955  ,  0.12900162],\n",
       "       [ 0.10136722,  0.06409666,  1.3900058 , ...,  0.07869086,\n",
       "         0.5670041 , -0.19467375],\n",
       "       [ 0.12369446,  0.3582304 ,  1.2054628 , ...,  0.38293025,\n",
       "         0.90999806,  0.0404312 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.sbert import SBERT\n",
    "\n",
    "model = SBERT()\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.accuracy_metrics import AccuracyMetrics\n",
    "from metrics.similarity_metrics import CosineSimilarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "class UnsupervisedBaselineTrainer:\n",
    "    def __init__(self, model, data_loader, similarity_metric, accuracy_metric):\n",
    "        self.model = model\n",
    "        self.data_loader = data_loader\n",
    "        self.similarity_metric = similarity_metric\n",
    "        self.accuracy_metric = accuracy_metric\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        The baseline isn't supposed to be trained, so this method is empty.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def test(self):\n",
    "        accuracy = 0\n",
    "        for x, y in tqdm(self.data_loader):\n",
    "            y = y[0]\n",
    "            rank_scores = []\n",
    "            y_score = self.model(y)\n",
    "            for rank, sentences in x.items():\n",
    "                sentences = list(chain(*sentences))\n",
    "                embeddings = self.model(sentences).mean(axis=0) # simple mean\n",
    "                rank_scores.append((self.similarity_metric(embeddings, y_score).cpu().detach().numpy()[0], rank))\n",
    "            sorted_rank_scores = sorted(rank_scores, key=lambda x: x[0], reverse=True)\n",
    "            accuracy += self.accuracy_metric(sorted_rank_scores)\n",
    "        return accuracy / len(self.data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:11<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 13.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = UnsupervisedBaselineTrainer(model, test_loader, CosineSimilarity(), AccuracyMetrics().accuracy)\n",
    "acc = trainer.test()\n",
    "print(f\"Accuracy: {acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
